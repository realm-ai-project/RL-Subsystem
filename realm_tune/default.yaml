realm_ai:
  algorithm: bayes # or random
  total_trials: 10 # total number of trials (inclusive of warmup_trials)
  warmup_trials: 5 # optional for bayes algorithm, number of "warmup" trials where random hyperparams are used. Default val is 5
  eval_window_size: 1 # optional, training run is evaluated by taking the average eps rew of past x episodes. Default val is 1

mlagents: # all values here (even those that are commented out) are used by the script. Other possible configs that are not here can be added at the discretion of the user.
  default_settings:
    trainer_type: ppo
    hyperparameters:
      batch_size: log_unif(64, 16384) # Means categorical
      buffer_size: log_unif(2048, 409600) # Automatic detection as int
      learning_rate: log_unif(0.0001, 0.01) # Automatic detection as float
      beta: log_unif(0.001, 0.03) # unif and log_unif exclude upper bound - [0.001, 0.01)
      epsilon: 0.2
      lambd: unif(0.95, 1.0)
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      hidden_units: [64, 256, 512, 1024]
      num_layers: unif(1, 3)
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: unif(0.9, 1.0)
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 100000
    time_horizon: log_unif(32, 8192)
    summary_freq: 10000