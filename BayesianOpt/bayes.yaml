realm_ai:
  behavior_name: 3DBallHard
  algorithm: bayes # or random
  num_trials: 10
  warmup_trials: 5 # number of "warmup" trials where random hyperparams are used
  eval_window_size: 3 # optional, training run is evaluated by taking the average eps rew of past x episodes. Default val is 1
  run_id: test # optional, specify to manually specify folder name, or to continue running

mlagents:
  env_settings:
    env_path: ../../../../Unity/envs/3dball/3dball
    env_args: null
    num_envs: 4
    seed: 0

  engine_settings:
    no_graphics: true
  
  checkpoint_settings:
    # run_id: anything # does not matter, will be generated automatically
    initialize_from: null
    load_model: false
    resume: false
    force: false # does not matter, overwritten as True through cli argument
    inference: false

  # torch_settings:
  #   device: cpu

  default_settings:
    trainer_type: ppo
    hyperparameters:
      batch_size: [64, 128, 256] # Means categorical
      buffer_size: log_unif(2000, 12000) # Automatic detection as int
      learning_rate: log_unif(0.0003, 0.01) # Automatic detection as float
      beta: log_unif(0.001, 0.01) # unif and log_unif exclude upper bound - [0.001, 0.01)
      epsilon: 0.2
      lambd: 0.99
      num_epoch: unif(1, 15)
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: [0.99, 0.95]
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 100000
    time_horizon: 1000
    summary_freq: 5000